{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2de67ed",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) para Investigación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7ac21b",
   "metadata": {},
   "source": [
    "## Paso 1: Carga y Previsualización de Datos\n",
    "Este paso incluye la carga del dataset y una primera exploración para entender las características del mismo. Usaremos un dataset sobre recurrencia del cáncer diferenciado de tiroides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac585b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Descargar el dataset desde UCI Machine Learning Repository\n",
    "differentiated_thyroid_cancer_recurrence = fetch_ucirepo(id=915)\n",
    "\n",
    "# Cargar las características (X) y la variable objetivo (y)\n",
    "X = differentiated_thyroid_cancer_recurrence.data.features\n",
    "y = differentiated_thyroid_cancer_recurrence.data.targets\n",
    "\n",
    "# Combinar las características y la variable objetivo en un solo DataFrame\n",
    "df = pd.concat([X, y], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7fe19c",
   "metadata": {},
   "source": [
    "## Paso 2: Análisis Exploratorio Inicial\n",
    "En esta sección, examinamos la estructura de los datos, verificamos tipos de columnas, valores faltantes y distribución de las variables. También visualizamos la distribución de la variable objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47815f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen de las primeras filas\n",
    "print(\"Primeras filas del dataset:\\n\", df.head())\n",
    "\n",
    "# Información sobre las columnas y tipos de datos\n",
    "print(\"\\nInformación del dataset:\\n\")\n",
    "print(df.info())\n",
    "\n",
    "# Estadísticas descriptivas generales\n",
    "print(\"\\nEstadísticas descriptivas:\\n\")\n",
    "print(df.describe(include='all'))\n",
    "\n",
    "# Visualización de la distribución de la variable objetivo\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='Recurred', data=df)\n",
    "plt.title('Distribución de la variable objetivo')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079d0cbb",
   "metadata": {},
   "source": [
    "## Paso 3: Preprocesamiento de Datos\n",
    "### Eliminación de Columnas Irrelevantes\n",
    "Eliminamos columnas que no son relevantes para el análisis, como identificadores únicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7281a75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar columnas irrelevantes si existen\n",
    "df = df.drop(columns=['ID', 'Ubigeo'], errors='ignore')\n",
    "print(\"Dataset después de eliminar columnas irrelevantes:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e17c40c",
   "metadata": {},
   "source": [
    "### Manejo de Valores Nulos\n",
    "Imputamos valores faltantes utilizando la mediana para variables numéricas y la moda para variables categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0615a352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar columnas numéricas y categóricas\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Imputar valores faltantes\n",
    "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "df[categorical_cols] = df[categorical_cols].fillna(df[categorical_cols].mode().iloc[0])\n",
    "\n",
    "# Verificar que ya no haya valores nulos\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e530b6",
   "metadata": {},
   "source": [
    "### División en Conjuntos de Entrenamiento y Prueba\n",
    "Dividimos los datos en conjuntos de entrenamiento (80%) y prueba (20%), asegurando la estratificación en la variable objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feada46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir características y variable objetivo\n",
    "X = df.drop(columns=['Recurred'])\n",
    "y = df['Recurred']\n",
    "\n",
    "# Dividir los datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print(\"Formas de los conjuntos:\")\n",
    "print(\"X_train:\", X_train.shape, \"X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bc0067",
   "metadata": {},
   "source": [
    "### Codificación de Variables Categóricas\n",
    "Convertimos las variables categóricas a formato numérico para que sean compatibles con algoritmos de machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daa358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar variables categóricas\n",
    "label_encoders = {}\n",
    "for col in X_train.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    X_train[col] = le.fit_transform(X_train[col])\n",
    "    X_test[col] = le.transform(X_test[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Codificar la variable objetivo\n",
    "le_target = LabelEncoder()\n",
    "y_train = le_target.fit_transform(y_train)\n",
    "y_test = le_target.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97153f3a",
   "metadata": {},
   "source": [
    "### Verificación Final de Conjuntos\n",
    "Comprobamos la distribución de la variable objetivo en los conjuntos de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779005ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar la distribución de la variable objetivo\n",
    "print(\"Distribución en el conjunto de entrenamiento:\", pd.Series(y_train).value_counts())\n",
    "print(\"Distribución en el conjunto de prueba:\", pd.Series(y_test).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172f33b2-835e-4d3f-b604-28a5a02a8fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar la distribución de la variable objetivo en los conjuntos de entrenamiento y prueba\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "sns.countplot(x=y_train, ax=axes[0])\n",
    "axes[0].set_title('Distribución en el conjunto de entrenamiento')\n",
    "sns.countplot(x=y_test, ax=axes[1])\n",
    "axes[1].set_title('Distribución en el conjunto de prueba')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9e841d",
   "metadata": {},
   "source": [
    "## Paso 4: Guardar los Datos Preprocesados\n",
    "Guardamos los conjuntos preprocesados en archivos CSV para futuras etapas de análisis o modelado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c7b5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar conjuntos preprocesados\n",
    "X_train.to_csv('X_train.csv', index=False)\n",
    "X_test.to_csv('X_test.csv', index=False)\n",
    "pd.DataFrame(y_train, columns=['Recurred']).to_csv('y_train.csv', index=False)\n",
    "pd.DataFrame(y_test, columns=['Recurred']).to_csv('y_test.csv', index=False)\n",
    "print(\"Conjuntos preprocesados guardados exitosamente.\")"
   ]
  },
  {
 "cells": [
  {
   "cell_type": "markdown",
   "id": "step5-title",
   "metadata": {},
   "source": [
    "## Paso 5: Evaluación Inicial de Modelos de Clasificación\n",
    "En esta sección, evaluamos el rendimiento de tres clasificadores comunes (Random Forest, MLP y Regresión Logística) usando el dataset original, sin generar ni balancear datos adicionales. Esto permitirá establecer un punto de comparación para futuras evaluaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import-libraries",
   "metadata": {},
   "source": [
    "### Importar Librerías Necesarias\n",
    "Incluimos las librerías para los clasificadores, métricas de evaluación y manejo de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-libraries-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, recall_score, confusion_matrix, matthews_corrcoef\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data",
   "metadata": {},
   "source": [
    "### Cargar los Conjuntos de Entrenamiento y Prueba\n",
    "Utilizamos los datos preprocesados generados en pasos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los conjuntos de datos\n",
    "X_train = pd.read_csv('X_train.csv')\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "y_train = pd.read_csv('y_train.csv').squeeze()\n",
    "y_test = pd.read_csv('y_test.csv').squeeze()\n",
    "\n",
    "# Verificar las formas de los conjuntos\n",
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "define-classifiers",
   "metadata": {},
   "source": [
    "### Definir los Clasificadores\n",
    "Especificamos los tres modelos que serán evaluados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-classifiers-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'MLP': MLPClassifier(random_state=42, max_iter=1000),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initialize-results",
   "metadata": {},
   "source": [
    "### Inicializar Resultados\n",
    "Creamos una lista para almacenar los resultados de cada modelo y sus métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initialize-results-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-evaluate",
   "metadata": {},
   "source": [
    "### Entrenar y Evaluar Modelos\n",
    "Entrenamos cada clasificador con los datos de entrenamiento y evaluamos sus predicciones en el conjunto de prueba utilizando varias métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-evaluate-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, clf in classifiers.items():\n",
    "    # Entrenar el clasificador\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicciones en el conjunto de prueba\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_pred_prob = clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calcular métricas\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc_roc = roc_auc_score(y_test, y_pred_prob)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "    # Guardar resultados\n",
    "    results.append({\n",
    "        'Modelo': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC-ROC': auc_roc,\n",
    "        'Specificity': specificity,\n",
    "        'MCC': mcc\n",
    "    })\n",
    "    \n",
    "    print(f\"{name}: Accuracy={accuracy:.4f}, Recall={recall:.4f}, F1={f1:.4f}, AUC-ROC={auc_roc:.4f}, Specificity={specificity:.4f}, MCC={mcc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-results",
   "metadata": {},
   "source": [
    "### Guardar Resultados\n",
    "Almacenamos las métricas en un archivo CSV para futuras comparaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-results-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir resultados a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Guardar en archivo CSV\n",
    "results_df.to_csv('resultados_clasificadores_sin_balanceo.csv', index=False)\n",
    "print(\"Resultados guardados exitosamente en 'resultados_clasificadores_sin_balanceo.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}